{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Traffic model step by step\n",
    "authors:\n",
    "- fezhao\n",
    "tags:\n",
    "- traffic management\n",
    "- data science\n",
    "- machine learning\n",
    "created_at: 2017-05-30\n",
    "updated_at: 2017-06-02\n",
    "tldr: Given the cost of the API calls, we would like to investigate the possibility of using machine learning to predict the efficiency of the API calls.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TL,DR: Given a partner and a hotel, use the model to predict whether there will be reservation call for the next day. The main takeaways are as follows:\n",
    "- The model metrics improves w.r.t. more features\n",
    "- The final model only blocks 4% of the reservations but block 87% of the zero reservations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the cost of the API calls, we would like to investigate the possibility of using machine learning to predict the efficiency of the API calls. As such, we could block the list API calls are unlikely to generate reservation, in order to saving the cost of API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large scale of the API dataset, here we did an data undersampling for fast model iterations and better data understanding. \n",
    "- We pick one partner DESPEGAR.COM\n",
    "- For DESPEGAR.COM, we randomly sample 1/10 of the hotels, the number of active hotels is 28,473\n",
    "- Each instance is the daily features for each hotel, we fill all zero for API calls for missing dates\n",
    "- Historical data: from 2015-01-01 to 2017-03-31\n",
    "- Train instance data: from 2016-01-01 to 2016-12-31, them we undersample the training data to make the dataset balance regarding to the label\n",
    "- Test instance data: from 2017-01-01 to 2017-03-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(model_path, X_test):\n",
    "    with open(model_path, 'rb') as fin:\n",
    "        gbm = pickle.load(fin)\n",
    "\n",
    "    y_preds = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat0 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Features：\n",
    " - list_count_sum_365d\n",
    " - avail_count_sum_365d\n",
    " - res_count_sum_365d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/fezhao/Projects/traffic_manager/data/test_feat1.csv', sep='|')\n",
    "df_test.drop(['hotelid', 'request_log_date'], axis=1, inplace=True)\n",
    "\n",
    "y_test = df_test['label']\n",
    "X_test = df_test[['list_count_sum_365d', 'avail_count_sum_365d', 'res_count_sum_365d']]\n",
    "\n",
    "y_pred_feat0 = get_preds('/Users/fezhao/Projects/traffic_manager/data/model_feat0.pkl', X_test)\n",
    "np.savetxt('/Users/fezhao/Projects/traffic_manager/data/y_pred_feat0.txt', y_pred_feat0, '%.8f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 Features：\n",
    " - list_count_sum_[365d, 30d, 7d, prev]\n",
    " - avail_count_sum_[365d, 30d, 7d, prev]\n",
    " - res_count_sum_[365d, 30d, 7d, prev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/fezhao/Projects/traffic_manager/data/test_feat1.csv', sep='|')\n",
    "df_test.drop(['hotelid', 'request_log_date'], axis=1, inplace=True)\n",
    "\n",
    "y_test = df_test['label']\n",
    "X_test = df_test.drop(['label'], axis=1)\n",
    "\n",
    "y_pred_feat1 = get_preds('/Users/fezhao/Projects/traffic_manager/data/model_feat1.pkl', X_test)\n",
    "np.savetxt('/Users/fezhao/Projects/traffic_manager/data/y_pred_feat1.txt', y_pred_feat1, '%.8f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 Features：\n",
    " - list_count_sum_[365d, 30d, 7d, prev]\n",
    " - avail_count_sum_[365d, 30d, 7d, prev]\n",
    " - res_count_sum_[365d, 30d, 7d, prev]\n",
    " - hotelpedia features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/fezhao/Projects/traffic_manager/data/test_feat2.csv', sep='|')\n",
    "df_test.drop(['hotelid', 'request_log_date', 'tnow_id'], axis=1, inplace=True)\n",
    "\n",
    "y_test = df_test['label']\n",
    "X_test = df_test.drop(['label'], axis=1)\n",
    "\n",
    "y_pred_feat2 = get_preds('/Users/fezhao/Projects/traffic_manager/data/model_feat2.pkl', X_test)\n",
    "np.savetxt('/Users/fezhao/Projects/traffic_manager/data/y_pred_feat2.txt', y_pred_feat2, '%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 60 Features：\n",
    " - list_count_sum_[365d, 30d, 7d, prev]\n",
    " - avail_count_sum_[365d, 30d, 7d, prev]\n",
    " - res_count_sum_[365d, 30d, 7d, prev]\n",
    " - hotelpedia features\n",
    " - derived features from date: day_of_week, month\n",
    " - derived ratio features:\n",
    "    * avail_list_ratio, res_avail_ratio, res_list_ratio\n",
    "    * prev_7d_ratio, 7d_30d_ratio, 30d_365d_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/fezhao/Projects/traffic_manager/data/test_feat3.csv', sep='|')\n",
    "df_test.drop(['hotelid', 'request_log_date', 'tnow_id'], axis=1, inplace=True)\n",
    "\n",
    "y_test = df_test['label']\n",
    "X_test = df_test.drop(['label'], axis=1)\n",
    "\n",
    "y_pred_feat3 = get_preds('/Users/fezhao/Projects/traffic_manager/data/model_feat3.pkl', X_test)\n",
    "np.savetxt('/Users/fezhao/Projects/traffic_manager/data/y_pred_feat3.txt', y_pred_feat3, '%.8f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_feat0 = np.loadtxt('/Users/fezhao/Projects/traffic_manager/data/y_pred_feat0.txt')\n",
    "y_pred_feat1 = np.loadtxt('/Users/fezhao/Projects/traffic_manager/data/y_pred_feat1.txt')\n",
    "y_pred_feat2 = np.loadtxt('/Users/fezhao/Projects/traffic_manager/data/y_pred_feat2.txt')\n",
    "y_pred_feat3 = np.loadtxt('/Users/fezhao/Projects/traffic_manager/data/y_pred_feat3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'feat0 model log loss: ', metrics.log_loss(y_test, y_pred_feat0)\n",
    "print 'feat1 model log loss: ', metrics.log_loss(y_test, y_pred_feat1)\n",
    "print 'feat2 model log loss: ', metrics.log_loss(y_test, y_pred_feat2)\n",
    "print 'feat3 model log loss: ', metrics.log_loss(y_test, y_pred_feat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_metrics(y_pred, y_test):\n",
    "    preds = y_pred >= 0.5\n",
    "    labels = y_test\n",
    "    cm = metrics.confusion_matrix(labels, preds)\n",
    "    plot_confusion_matrix(cm, classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(y_pred_feat0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(y_pred_feat1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(y_pred_feat2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(y_pred_feat3, y_test)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}